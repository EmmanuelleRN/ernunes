---
title: Conditional Probability
author: Emmanuelle R. Nunes
date: September 19 2021
slug: September 19 2021-introduction-to-probability
categories: []
tags: []
subtitle: and Independence
summary: ''
authors: []
lastmod: '2021-09-19T15:52:58+01:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---

For any two events A and B, with $\mathbb{P}(B) > 0$, we define the conditional probability of A given B ($\mathbb{P}(A|B)$) as

$$\mathbb{P}(A|B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}$$

**Example:** We throw a dice once, and it lands on an even number. What is the probability of this number is 2?

We can define A as "dice shows number 2", and B as "dice result is even", we have then that A = {2}, B = {2, 4, 6} and $A \cap B = {2}$, then

$$\mathbb{P}(A|B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)} = \frac{1}{3}$$

## Independence

Independence between two or more variables can help us to ease some of our analysis. We say that two events A and B are independent if and only if $\mathbb{P}(A \cap B) = \mathbb{P}(A) \mathbb{P}(B)$, i.e., two events are independent if the incidence of one event does not affect the probability of the other event. If the incidence of one event does affect the probability of the other event, then the events are dependent.

The concept of conditional probability is closely related to independent events, and we can define independence between events using conditional probability.

Two events $A$ and $B$ are independent if:

$$\mathbb{P}(A\mid B) = \mathbb{P}(A \mid B^c) \text{ and } \mathbb{P}(B\mid A) = \mathbb{P}(B\mid A^c)$$

Two events $A$ and $B$ are dependent if :

$$\mathbb{P}(A\mid B) \neq \mathbb{P}(A \mid B^c) \text{ or } \mathbb{P}(B\mid A) \neq \mathbb{P}(B\mid A^c)$$

**Example:** Two fair 6-sided dice are rolled, one red and one blue. 
  $A$ = the red die's result is 3. 
  $B$ = the blue die's result is 4. 
  $C$ = the event that the sum of the rolls is 7. 
Are $A$, $B$ and $C$ mutually independent?

$$\mathbb{P}(A|B) = \frac{1}{6} = \mathbb{P}(A \mid B^c) \implies \text{A and B are independent}$$

$$\mathbb{P}(A|C) = \frac{1}{6} = \mathbb{P}(A \mid C^c) \implies \text{A and C are independent}$$

$$\mathbb{P}(B|C) = \frac{1}{6} = \mathbb{P}(B \mid C^c) \implies \text{B and C are independent}$$

Theses events are pairwise independent. However, in order for all three events to be mutually independent, each event must be independent with each intersection of the other events.

$$\mathbb{P}\left(A\mid (B\cap C)\right) = 1 \text{ and } P\left(A\mid (B\cap C)^c\right)=\dfrac{1}{7}$$
 
These are not equal, $A$, $B$, and $C$ are mutually dependent.

# Bayes theorem

One of the most essential conditional probability entities is the one from the Bayes theorem. The formula is given by:

$$\mathbb{P}(A \mid B) = \frac{\mathbb{P}(B \mid A)\mathbb{P}(A)}{\mathbb{P}(B)}$$